{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"smile_train.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"b7dn7pRPaqtN","colab_type":"code","outputId":"3e38b1dc-3427-4996-bcc6-1ff1272db159","executionInfo":{"status":"ok","timestamp":1565073187358,"user_tz":-120,"elapsed":19652,"user":{"displayName":"Arunava Maulik","photoUrl":"","userId":"02529691368075628490"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wFr9iI-Pjb55","colab_type":"code","colab":{}},"source":["import os\n","os.chdir('/content/drive/My Drive/smile')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B9a6FKD1jj5S","colab_type":"code","outputId":"8205300f-dd8f-47bf-f050-921372669f67","executionInfo":{"status":"ok","timestamp":1565073189115,"user_tz":-120,"elapsed":5883,"user":{"displayName":"Arunava Maulik","photoUrl":"","userId":"02529691368075628490"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import random\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","# from torchsummary import summary\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from sklearn.model_selection import train_test_split\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch.utils import data\n","from torchvision import models\n","from tqdm import tqdm\n","from PIL import Image\n","import glob\n","import pickle\n","\n","RANDOM_SEED = 41\n","np.random.seed(RANDOM_SEED)\n","\n","random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f578f3d7c70>"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"uHzysLzkjljY","colab_type":"code","colab":{}},"source":["def get_model_regression(out_dim=1024, pretrained=False):\n","    model = models.resnet18(pretrained=pretrained)\n","    nb_features = model.fc.in_features\n","    model.fc = nn.Sequential(nn.Linear(nb_features, out_dim), nn.Sigmoid())\n","    #model.fc_1 = nn.Sigmoid()\n","    if target_channels == 1:\n","        model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zsHxmjTf-Q0q","colab_type":"code","colab":{}},"source":["def custom_loss(anchor, positive_negative, label):\n","  cosim = nn.CosineSimilarity()\n","  cosim_output = cosim(anchor, positive_negative)\n","  bceloss = torch.nn.BCELoss()\n","  loss = bceloss(1 - cosim_output, label)\n","  return loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DeynD1F4N8eC","colab_type":"code","colab":{}},"source":["def create_array(folder):\n","  image_map = {}\n","  for filename in glob.glob(f'{folder}/*'):\n","#     image = Image.open(filename).convert('RGB')\n","#     image = image.resize((target_width, target_height))\n","#     image = np.array(image) / 255.\n","    feature_array = np.load(filename)\n","    image_map[filename] = feature_array\n","  with open('image_mapping_dictionary.pickle', 'wb') as handle:\n","    pickle.dump(image_map, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t5wuZUut22Pp","colab_type":"code","colab":{}},"source":["def load_checkpoint(model, optimizer, filename='checkpoint.pth.tar', checkpoint_epoch=0):\n","    # Note: Input model & optimizer should be pre-defined.  This routine only updates their states.\n","    start_epoch = checkpoint_epoch\n","    if os.path.isfile(filename):\n","        print(f\"=> loading checkpoint '{filename}'\")\n","        checkpoint = torch.load(filename)\n","        start_epoch = checkpoint['epoch']\n","        model.load_state_dict(checkpoint['state_dict'])\n","        optimizer.load_state_dict(checkpoint['optimizer'])\n","        print(f\"=> loaded checkpoint '{filename}' (epoch {checkpoint['epoch']})\")\n","    else:\n","        print(f\"=> no checkpoint found at '{filename}'\")\n","        start_epoch = 0\n","    return model, optimizer, start_epoch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zWXCIrrHjvU7","colab_type":"code","colab":{}},"source":["class Smile(data.Dataset):\n","\n","    def __init__(self, X, pickle_file):\n","        self.X = X\n","        with open(f'{pickle_file}', 'rb') as handle:\n","          self.image_map = pickle.load(handle)\n","          \n","    def __getitem__(self, index):\n","        doublets = np.zeros((2, target_width, target_height, target_channels))\n","        X = self.X[index]\n","        doublets[0] = self.image_map[X[0]]\n","        doublets[1] = self.image_map[X[1]]\n","        doublets = torch.from_numpy(doublets.transpose((0, 3, 1, 2))).type(torch.FloatTensor)\n","        return doublets, torch.tensor(int(X[2])).type(torch.FloatTensor)\n","\n","    def __len__(self):\n","        return len(self.X)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VyF-AdPF9R2r","colab_type":"code","colab":{}},"source":["def train(weights_folder, data_folder, X_train, X_val, params, pretrained = False, checkpoint_epoch=0):\n","    epochs = params['epochs']\n","    batch_size = params['batch_size']\n","    lr = params['learning_rate']\n","    weight_decay = params['weight_decay']\n","    #alpha = params['alpha']\n","    model_name = params[\"model_name\"]\n","\n","\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(42)\n","    torch.backends.cudnn.deterministic = True\n","\n","    train_dataset = Smile(X_train, data_folder)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0,\n","                              worker_init_fn=np.random.seed(42))\n","    val_dataset = Smile(X_val, data_folder)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=0,\n","                              worker_init_fn=np.random.seed(42))\n","    \n","    model = get_model_regression(pretrained=pretrained)\n","    \n","    if torch.cuda.is_available():\n","        model.cuda()\n","        \n","    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5, verbose=True)\n","    \n","    \n","    weight_filename = f'{weights_folder}/{model_name}_{checkpoint_epoch}.pt'\n","    model, optimizer, start_epoch = load_checkpoint(model, optimizer, filename=weight_filename,\n","                                                    checkpoint_epoch=checkpoint_epoch)\n","    if torch.cuda.is_available():\n","        model = model.cuda()\n","    for state in optimizer.state.values():\n","        for k, v in state.items():\n","            if isinstance(v, torch.Tensor):\n","                if torch.cuda.is_available():\n","                    state[k] = v.cuda()\n","    \n","    \n","    valid_loss_min = np.Inf\n","    train_size = len(train_loader)\n","    validation_size = len(val_loader)\n","\n","    for epoch in range(start_epoch+1, epochs+1):\n","        print(epoch)\n","        train_loss = 0.\n","        valid_loss = 0.\n","\n","        # TRAIN\n","        with tqdm(total=train_size, desc=f\"Training Epoch {epoch}\",\n","                  bar_format=\"{l_bar}{bar} [ time left: {remaining} ]\") as pbar:\n","            model.train()\n","            for inputs, label in train_loader:\n","                #print(inputs.shape)\n","                pbar.update(1)\n","                if torch.cuda.is_available():\n","                    inputs = inputs.cuda()\n","                    label = label.cuda()\n","                optimizer.zero_grad()\n","                \n","                input_0 = inputs[:, 0]\n","                #print(input_0.shape)\n","                output_0 = model(input_0)\n","                input_1 = inputs[:, 1]\n","                output_1 = model(input_1)\n","                loss = custom_loss(output_0, output_1, label)\n","                loss.backward()\n","                optimizer.step()\n","                train_loss += loss.item() * inputs.size(0)\n","\n","        # VALIDATION\n","        with tqdm(total=validation_size, desc=f\"Validating\",\n","                  bar_format=\"{l_bar}{bar} [ time left: {remaining} ]\") as pbar:\n","            model.eval()\n","            for inputs,label in val_loader:\n","                pbar.update(1)\n","                if torch.cuda.is_available():\n","                    inputs = inputs.cuda()\n","                    label = label.cuda()\n","                optimizer.zero_grad()           \n","                input_0 = inputs[:, 0]\n","                #print(input_0.shape)\n","                output_0 = model(input_0)\n","                input_1 = inputs[:, 1]\n","                output_1 = model(input_1)\n","                loss = custom_loss(output_0, output_1, label)\n","                valid_loss += loss.item() * inputs.size(0)\n","\n","            train_loss = train_loss / len(train_loader.dataset)\n","            valid_loss = valid_loss / len(val_loader.dataset)\n","            print(f'Epoch: {epoch} \\tTraining loss: {train_loss} \\tValidation loss: {valid_loss}')\n","\n","        scheduler.step(valid_loss)\n","\n","        # MODEL SAVING\n","        if valid_loss <= valid_loss_min:\n","            print(f'Validation loss decreased ({valid_loss_min} --> {valid_loss}).  Saving model ...')\n","            state = {'epoch': epoch, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}\n","            torch.save(state, f'{weights_folder}/{model_name}_{epoch}.pt')\n","            valid_loss_min = valid_loss\n","\n","    print(f\"Best validation Loss: {valid_loss_min}\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bFVVP5Y69cph","colab_type":"code","outputId":"57500707-dd3e-40d8-f90c-732d0a0cd1ba","executionInfo":{"status":"error","timestamp":1565084868716,"user_tz":-120,"elapsed":4898487,"user":{"displayName":"Arunava Maulik","photoUrl":"","userId":"02529691368075628490"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["if __name__ == '__main__':\n","    doublet_data = np.load('doublets.npy')\n","    validation_size = 0.2\n","    target_width, target_height, target_channels = 224, 224, 3\n","    X_train, X_val = train_test_split(doublet_data, test_size=validation_size, random_state=RANDOM_SEED)\n","    create_array('single_images')\n","    train('weights', 'image_mapping_dictionary.pickle', X_train, X_val, params={\n","        \"epochs\": 300,\n","        \"batch_size\": 8,\n","        \"learning_rate\": 5e-5,\n","        \"weight_decay\": 0,\n","        \"model_name\": \"best_model\"\n","        #\"alpha\": 0.3\n","    }, pretrained = True, checkpoint_epoch=0)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["\rTraining Epoch 1:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["=> no checkpoint found at 'weights/best_model_0.pt'\n","1\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 1: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1 \tTraining loss: 0.8874515952459022 \tValidation loss: 0.7145727556143234\n","Validation loss decreased (inf --> 0.7145727556143234).  Saving model ...\n"],"name":"stdout"},{"output_type":"stream","text":["\rTraining Epoch 2:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["2\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 2: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 2 \tTraining loss: 0.6435202465573353 \tValidation loss: 0.6646755088621111\n","Validation loss decreased (0.7145727556143234 --> 0.6646755088621111).  Saving model ...\n"],"name":"stdout"},{"output_type":"stream","text":["\rTraining Epoch 3:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["3\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 3: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 3 \tTraining loss: 0.5802918441927255 \tValidation loss: 0.6448616724405716\n","Validation loss decreased (0.6646755088621111 --> 0.6448616724405716).  Saving model ...\n"],"name":"stdout"},{"output_type":"stream","text":["\rTraining Epoch 4:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["4\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 4: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 4 \tTraining loss: 0.5179905409021164 \tValidation loss: 0.598889056070527\n","Validation loss decreased (0.6448616724405716 --> 0.598889056070527).  Saving model ...\n"],"name":"stdout"},{"output_type":"stream","text":["\rTraining Epoch 5:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["5\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 5: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 5 \tTraining loss: 0.4546487204619308 \tValidation loss: 0.5936296460788641\n","Validation loss decreased (0.598889056070527 --> 0.5936296460788641).  Saving model ...\n"],"name":"stdout"},{"output_type":"stream","text":["\rTraining Epoch 6:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["6\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 6: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 6 \tTraining loss: 0.3983789902124832 \tValidation loss: 0.5582858010904113\n","Validation loss decreased (0.5936296460788641 --> 0.5582858010904113).  Saving model ...\n"],"name":"stdout"},{"output_type":"stream","text":["\rTraining Epoch 7:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["7\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 7: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 7 \tTraining loss: 0.3460007797203847 \tValidation loss: 0.5456836820983175\n","Validation loss decreased (0.5582858010904113 --> 0.5456836820983175).  Saving model ...\n"],"name":"stdout"},{"output_type":"stream","text":["\rTraining Epoch 8:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["8\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 8: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 8 \tTraining loss: 0.31076214461406665 \tValidation loss: 0.5311264316537487\n","Validation loss decreased (0.5456836820983175 --> 0.5311264316537487).  Saving model ...\n"],"name":"stdout"},{"output_type":"stream","text":["\rTraining Epoch 9:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["9\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 9: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 9 \tTraining loss: 0.2670586167320387 \tValidation loss: 0.5271406040707631\n","Validation loss decreased (0.5311264316537487 --> 0.5271406040707631).  Saving model ...\n"],"name":"stdout"},{"output_type":"stream","text":["\rTraining Epoch 10:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["10\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 10: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 10 \tTraining loss: 0.24452369309850594 \tValidation loss: 0.514514517139143\n","Validation loss decreased (0.5271406040707631 --> 0.514514517139143).  Saving model ...\n"],"name":"stdout"},{"output_type":"stream","text":["\rTraining Epoch 11:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["11\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 11: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 11 \tTraining loss: 0.22579906595620647 \tValidation loss: 0.5088793616241484\n","Validation loss decreased (0.514514517139143 --> 0.5088793616241484).  Saving model ...\n"],"name":"stdout"},{"output_type":"stream","text":["\rTraining Epoch 12:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["12\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 12: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 12 \tTraining loss: 0.2003293585588238 \tValidation loss: 0.49207874046110395\n","Validation loss decreased (0.5088793616241484 --> 0.49207874046110395).  Saving model ...\n"],"name":"stdout"},{"output_type":"stream","text":["\rTraining Epoch 13:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["13\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 13: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n","Training Epoch 14:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 13 \tTraining loss: 0.18017319176457267 \tValidation loss: 0.492658373535569\n","14\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 14: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 14 \tTraining loss: 0.16397552031523255 \tValidation loss: 0.4918032334366841\n","Validation loss decreased (0.49207874046110395 --> 0.4918032334366841).  Saving model ...\n"],"name":"stdout"},{"output_type":"stream","text":["\rTraining Epoch 15:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["15\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 15: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n","Training Epoch 16:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 15 \tTraining loss: 0.14634742101849016 \tValidation loss: 0.5051157787108599\n","16\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 16: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n","Training Epoch 17:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 16 \tTraining loss: 0.1371329747863225 \tValidation loss: 0.4980725851855171\n","17\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 17: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n","Training Epoch 18:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 17 \tTraining loss: 0.12292979645695704 \tValidation loss: 0.5117937194100067\n","18\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 18: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n","Training Epoch 19:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 18 \tTraining loss: 0.10979818116956905 \tValidation loss: 0.5227798024887469\n","19\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 19: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n","Training Epoch 20:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 19 \tTraining loss: 0.10049800571165422 \tValidation loss: 0.529929854025814\n","20\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 20: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n","Training Epoch 21:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 20 \tTraining loss: 0.0916568990449296 \tValidation loss: 0.5503043837511717\n","Epoch    19: reducing learning rate of group 0 to 2.5000e-05.\n","21\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 21: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n","Training Epoch 22:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 21 \tTraining loss: 0.06825763504298876 \tValidation loss: 0.5681451408303718\n","22\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 22: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n","Training Epoch 23:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 22 \tTraining loss: 0.05875003527043693 \tValidation loss: 0.5847846849230743\n","23\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 23: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n","Training Epoch 24:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 23 \tTraining loss: 0.05481936185926532 \tValidation loss: 0.5893349229844649\n","24\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 24: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n","Training Epoch 25:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 24 \tTraining loss: 0.05168680634849997 \tValidation loss: 0.5700368987980173\n","25\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 25: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n","Training Epoch 26:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 25 \tTraining loss: 0.04404825021012394 \tValidation loss: 0.581368145078365\n","26\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 26: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n","Training Epoch 27:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 26 \tTraining loss: 0.042426922245284736 \tValidation loss: 0.6339633737357139\n","Epoch    25: reducing learning rate of group 0 to 1.2500e-05.\n","27\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 27: 100%|██████████ [ time left: 00:00 ]\n","Validating: 100%|██████████ [ time left: 00:00 ]\n","Training Epoch 28:   0%|           [ time left: ? ]"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 27 \tTraining loss: 0.035071018608564986 \tValidation loss: 0.6344043984689486\n","28\n"],"name":"stdout"},{"output_type":"stream","text":["Training Epoch 28: 100%|██████████ [ time left: 00:00 ]\n","Validating:  92%|█████████▏ [ time left: 00:01 ]\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-32fa28e03ac0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;34m\"model_name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"best_model\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#\"alpha\": 0.3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     }, pretrained = True, checkpoint_epoch=0)\n\u001b[0m","\u001b[0;32m<ipython-input-9-947ae63488cf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(weights_folder, data_folder, X_train, X_val, params, pretrained, checkpoint_epoch)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0minput_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;31m#print(input_0.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0moutput_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0minput_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0moutput_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mweak_script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m def batch_norm(input, running_mean, running_var, weight=None, bias=None,\n\u001b[1;32m   1671\u001b[0m                training=False, momentum=0.1, eps=1e-5):\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"uPR7zCLKaG9-","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}